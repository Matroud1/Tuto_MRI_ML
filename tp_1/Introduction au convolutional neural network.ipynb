{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aujourd'hui, il existe beaucoup de produits dit \"d'Intelligence Artificielle (IA)\", ces applications utilisent majoritairement du Machine Learning (ML), qui est un sous-domaine de l'IA, comme vous pouvez le voir ci-dessous. Le machine learning est un champ d'étude qui permet à des programmes de pouvoir résoudre des problèmes à partir de données sans les avoir explicitement programmé. Le deep learning est seulement un des nombreux algorithmes d'apprentissage du machine learning. \n",
    "\n",
    "<img src=\"data/intelligence_artificielle.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous allons nous concentrer sur les problèmatiques d'apprentissage supervisé. Nous allons avoir un jeu de données avec des variables explicatives A et des labels B. Le but de notre algorithme, sera d'apprendre à transformer A en B. Comme vous pouvez le voir ci-dessous, la première étape sera l'entraînement, où l'on donnera des données d'entraînement A et B à un algorithme d'apprentissage. Une fois l'entraînement terminé, l'algorithme nous donne un modèle mathématique. Ce modèle pourra prendre des nouvelles données A' afin de pouvoir estimer leurs résultats B'\n",
    "\n",
    "<img src=\"data/machine_learning.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deep learning est un algorithme de machine learning basé sur des neurones artificielles. Ces neurones sont des unités de calculs, ils prennt en entrée des informations, les transforment en une valeur et transmettent cette valeur à d'autres neurones.\n",
    "\n",
    "<img src =\"data/neurone.png\" width=\"600\" >\n",
    "\n",
    "Vous pouvez le voir ci-dessous, si l'on met des neurones artificielles en réseau, nous obtenons un réseau de neurones qui permet de prendre en entrée des données A et de changer la représentation de ces données afin de pouvoir transformer plus facilement A en B.\n",
    "\n",
    "<img src =\"data/réseau_de_neurones.png\" width=\"600\" >\n",
    "\n",
    "Initiallement, cet algorithme était censé représenter artificiellement le comportement du cerveau humain. Aujourd'hui, son fonctionnement est bien loin du fonctionnement du cerveau humain même s'il y a encore du vocabulaire hérité de cette inspiration biologique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantage du deep learning réside dans la superposition de couches. Cette superposition permet de changer la représentation des données d'entrées de notre réseau pour mettre en valeur différenes caractéristiques de notre jeux de données. Cette nouvelle représentation est élaboré afin de résoudre notre problème plus efficacement. Comme vous pouvez le voir ci-dessous, ça remplace en partie le processus de feature engineering indispensable aux modèles de machines learning classique. \n",
    "\n",
    "<img src =\"data/ml_vs_dl.png\" width=\"700\" >\n",
    "\n",
    "Cette force, a permi le développement d'algorithme de deep learning très robuste capable de mieux comprendre les données non structurés tels que du texte, du son et des images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les architectures de Convolutional Neural Network (CNN)\n",
    "\n",
    "Comme vous l'avons vue précédemment, le principal avantage des réseaux de neurones par rapport aux algorithmes de machine learning traditionnels est que les algorithmes de deep learning apprennent des représentations par eux-mêmes, alors que dans le machine learning traditionnel, on créé des variables à la main sensé être une meilleure représentation des données. Eh bien, c'est vrai pour les réseaux de neurones de type \"fully connceted\" qui ne sont constitués que de couches entièrement connectées. Mais il est très difficile de les entraîner pour des entrées de haute dimension comme les images.\n",
    "\n",
    "Lorsque vous utilisez une architecture de CNN, vous utilisez deux types de fonctionnalités artisanales : les convolutional layers (les filtres de convolution) et les poolign layers (les filtres de regroupement).\n",
    "\n",
    "Le concepteur du CNN pour la classification des images a examiné les données d'entrée (c'est ce que font les ingénieurs en machine learning traditionnels pour inventer des fonctionnalités) et a décidé que des patchs de pixels proches les uns des autres contiennent des informations qui pourraient aider à la classification, et en même temps réduire le nombre de paramètres. Vous pouvez voir l'application d'un patch sur une image ci-dessous.\n",
    "\n",
    "<img src=\"data/application_de_patchs.gif\" width=\"500\" >\n",
    "\n",
    "En effet, l'application de patchs sur une image permet de transformer l'image et de faire ressortir certaines de ces caractéristiques comme vous pouvez le voir ci-dessous.\n",
    "\n",
    "<img src=\"data/filters.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but du CNN est de transformer notre image de départ en vecteur qui serait la représentation vectorielle des caractéristiques de notre image. \n",
    "\n",
    "<img src=\"data/conv_nn.png\" width=\"600\" >\n",
    "\n",
    "Une fois que nous avons extrait les caractéristiques de notre image sous forme de vecteur, nous pouvons utiliser cette représentation afin de résoudre un problème lié à notre image. Sur l'illustration ci-dessous, vous pouvez bien voir les deux différentes parties qui consistuent notre réseau. \n",
    "\n",
    "<img src=\"data/CNN.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne vous inquiétez pas, vous n'allez pas avoir besoin de connaître toutes les mathématiques qui se cachent derrière les réseaux convolutionel pour pouvoir les utiliser. \n",
    "Grâce à Tensorflow et sa sur-couche Keras, vous pouvez construire un modèle en quelques cliques.\n",
    "\n",
    "### Sélection du matériel\n",
    "\n",
    "Avant de commencer nous allons sélectionné le matériel adapté à nos calculs. Le deep learning à besoin de cartes graphiques (GPU) afin de réduire \n",
    "\n",
    "### Importation des packages\n",
    "\n",
    "On va commencer par importer les packages nécessaires à l'élaboration de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations des données\n",
    "\n",
    "Maintenant que nos outils sont chargés, nous allons charger nos données.\n",
    "\n",
    "Cliquez sur le lien ci-dessous : \n",
    "\n",
    "https://drive.google.com/open?id=1Wg3FnIydOdu6twEpu3iB8inZghsIIV1d\n",
    "\n",
    "Cliquer droit sur le dossier data et appuyer sur ajouter à mon drive.\n",
    "\n",
    "<img src=\"data/google_drive.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécutez la cellule ci-dessous et appuyer sur le lien proposé. \n",
    "\n",
    "Suivez les instructions et copier le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont maintenant dans votre environnement collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('/content/gdrive/My Drive/data/train_signs.h5', \"r\")\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "test_dataset = h5py.File('/content/gdrive/My Drive/data/test_signs.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) \n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) \n",
    "\n",
    "classes = np.array(test_dataset[\"list_classes\"][:]) \n",
    "  \n",
    "train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "input_shape = train_set_x_orig[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exemple, nous allons créer un modèle de deep learning capable de reconnaître quel chiffre fait la main une photo. Comme vous pouvez le voir ci-dessous, nous avons 5 classes. \n",
    "\n",
    "<img src=\"data/signes.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez directement voir les exemples depuis le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 0\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(train_set_y_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir ci-dessous que nos images sont en trois dimensions 64 x 64 x 3.\n",
    "\n",
    "La première dimension de 64 correspond à la hauteur en pixel de la photo, ici 64 pixels.\n",
    "\n",
    "La deuxième dimension de 64 correspond à la largeur en pixel de la photo, ici 64 pixels.\n",
    "\n",
    "La troisième dimension correspond aux intensités de rouge, de vert et de bleu nécessaire pour former la couleur du pixel.\n",
    "\n",
    "<img src=\"data/RGB-color-model.jpg\" width=\"300\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set_x_orig[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer des images en informatique, il n'y a pas une intensité par couleur, ce serait trop complexe à organiser. Pour remédier à cela, nous avons pris trois couleurs (rouge, vert et bleu) et chaque couleur sera une combinaison d'intensité de ces trois couleurs. Le schéma ci-dessous va sûrement vous aider à comprendre le problème. \n",
    "\n",
    "<img src=\"data/image_en_rgb.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Pour des raisons d'optimisation, nous voulons que les données d'entrées de notre modèle soient petit, voir compris entre 0 et 1.\n",
    "\n",
    "La bonne nouvelle, c'est que les intensités d'une image sont toujours comprises entre 0 et 255. Nous allons donc utiliser la min-max normalisation afin de réduire la valeur des intensités de nos images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valeur maximum de nos images : ',np.min(train_set_x_orig))\n",
    "print('Valeur minimum de nos images : ', np.max(train_set_x_orig))\n",
    "\n",
    "X_train = train_set_x_orig.astype('float32')/255\n",
    "X_test = test_set_x_orig.astype('float32')/255\n",
    "\n",
    "print('Valeur maximum de nos images normalisées : ',np.min(X_train))\n",
    "print('Valeur minimum de nos images normalisées : ',np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans nos vecteurs \"train_set_y_orig\" et \"test_set_y_orig\" nous avons le chiffre correspond à l'image de la main.\n",
    "\n",
    "Nous allons transformer nos valeurs en hot vecteur, c'est-à-dire au lieu d'avoir la valeur 5 on aura un vecteur avec un 1 à la 5ème case. \n",
    "\n",
    "<img src=\"data/hot_vecteur.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set_y_orig.shape)\n",
    "print(test_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.eye(6)[train_set_y_orig.reshape(-1)]\n",
    "Y_test = np.eye(6)[test_set_y_orig.reshape(-1)]\n",
    "print(Y_train[150, :])\n",
    "print((train_set_y_orig[:, 150]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de notre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous allons créer un modèle basique de CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer notre modèle par une couche de convolution. Comme vous pouvez voir ci-dessous, c'est simplement l'application d'un filtre sur notre image pour extraire des caractéristiques.\n",
    "\n",
    "<img src=\"data/convolution_anim.gif\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(64,64,3)))\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant ajouter une couche de max-pooling. Comme vous pouvez voir ci-dessous, c'est simplement la sélection de l'intensité la plus grande parmi une sélection de pixels.\n",
    "\n",
    "<img src=\"data/pooling_anim.gif\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons extrait des informations de notre image, nous allons transformer ces représentations en vecteur.\n",
    "\n",
    "<img src=\"data/flatten.gif\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir, nous allons utiliser des couches entièrement connectées pour prédire l'appartenance de nos observations à nos classes.\n",
    "\n",
    "<img src=\"data/fully_connected.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle est assemblé, nous pouvons maintenant le visualiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une représentation plus visuelle du modèle.\n",
    "\n",
    "<img src=\"data/baseline.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voilà à la dernière étape, l'entraînement de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.01), metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs = 100,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir ce notebook, nous allons sauvegarder les paramètres de notre modèle si nous voulons l'utiliser à nouveau plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
