{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important: understanding cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why isn't MSE well suited for classification ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-entropy is a loss function, just like MSE\n",
    "you want it as small as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, calculate probabilities that sum to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat      5\n",
       "dog      4\n",
       "horse    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = {'cat':5, 'dog':4, 'horse': 2}\n",
    "preds = pd.Series(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat      148.413159\n",
       "dog       54.598150\n",
       "horse      7.389056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([preds, exp_preds])\n",
    "df['sum'] = np.sum(df, axis=1)\n",
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['softmax'] = df[1] / df[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>softmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>cat</td>\n",
       "      <td>5.0</td>\n",
       "      <td>148.413159</td>\n",
       "      <td>0.705385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dog</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.598150</td>\n",
       "      <td>0.259496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>horse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>0.035119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sum</td>\n",
       "      <td>11.0</td>\n",
       "      <td>210.400365</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1   softmax\n",
       "cat     5.0  148.413159  0.705385\n",
       "dog     4.0   54.598150  0.259496\n",
       "horse   2.0    7.389056  0.035119\n",
       "sum    11.0  210.400365  1.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then, find a way to penalize highly the model if you don't have the right (highest) probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_excel('excel files/entropy_example.xlsx', sheet_name='log_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isCat</th>\n",
       "      <th>isDog</th>\n",
       "      <th>Preds</th>\n",
       "      <th>logPredCat</th>\n",
       "      <th>logPredDog</th>\n",
       "      <th>NLL</th>\n",
       "      <th>idx</th>\n",
       "      <th>idxPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>-0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.008774</td>\n",
       "      <td>-1.69897</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.045757</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>-0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.045757</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.045757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isCat  isDog  Preds  logPredCat  logPredDog       NLL  idx   idxPred\n",
       "0      1      0   0.50   -0.301030    -0.30103  0.301030    1 -0.301030\n",
       "1      1      0   0.98   -0.008774    -1.69897  0.008774    1 -0.008774\n",
       "2      0      1   0.90   -0.045757    -1.00000  1.000000    2 -1.000000\n",
       "3      0      1   0.50   -0.301030    -0.30103  0.301030    2 -0.301030\n",
       "4      1      0   0.90   -0.045757    -1.00000  0.045757    1 -0.045757"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01005033585350145 4.605170185988091\n"
     ]
    }
   ],
   "source": [
    "isCat = 0\n",
    "isDog = 1\n",
    "PredsCat = 0.99\n",
    "PredsDog = 1 - PredsCat\n",
    "logPredCat = -np.log(PredsCat)\n",
    "logPredDog = -np.log(PredsDog)\n",
    "print(logPredCat, logPredDog)\n",
    "# here, we keep logPredDog, because we were supposed to predict a dog (and we were 99% sure it was a cat...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cross_entropy.jpg\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\"> source </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But, just like MSE, it doesn't suit every problem !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of a setup where neither MSE or Cross-Entropy would make sense ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You try to predict somebody's age using their picture. Which loss would you use and why ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This won't work... some outputs will be put to infinity because of the .exp() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(output):\n",
    "    return (output.exp() / output.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max(-1)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead we can use the log-sum-exp-trick:\n",
    "https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:, None]).exp().sum(-1).log()\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log likelihood\n",
    "def nll(output, y_train):\n",
    "    # we use y_train to know which one\n",
    "    # of the ten predictions we want to use\n",
    "    return -output[range(y_train.shape[0]), y_train].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-102.8454, -304.8141,  -45.5277,  ...,   -0.7240, -160.0200,\n",
       "          -5.2032])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that way we get only 60000 numbers\n",
    "log_softmax(output)[range(60000), y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(170.4121)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from which we take the mean, and we have our loss\n",
    "nll(log_softmax(output), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
